논문 브리핑


<Lesion Analysis and Diagnosis with Mask-RCNN>
1. 논문 주제
 - 이 논문은 '병변을 Mask-RCNN으로 진단하는 것'에 대한 주제이다.
 - 이 논문은 ISIC 2018 Challenge의 과제로 Mask R-CNN을 이용한다.
   task 1 : 병변의 경계 분할(lesion boundary segmentation)
   task 2 : 병변 속성 검출(lesion attributes detection)
   task 3 : 병변 진단(lesion diagnosis)


2. 이용 툴
 - Mask R-CNN을 이용하기 위해서 Keras2와 Tensorflow3를 Python 3.5를 이용해서 구현했다.
 - 모든 실험은 8Gb의 램을 가지는 NVIDIA Geforce 1080에서 실행 되었다.
 - 이 연구는 Git 레포지터리에서 소스 코드와 디테일한 설정들을 볼 수 있다.


3. Training Data, Augmentation, Scoring
 (1) Training Data
  1) ISIC 2018 Challenge는 이미지의 경계 분할과 탐지를 위해 다음과 같은 데이터를 준다.
   - 2594개의 training 병변 이미지
   - 병변의 위치를 나타내는 2594개의 binary mask images
   - 진피(병변)의 위치를 나타내는 12970개의 binary images(training 이미지당 5개씩)

  2) 병의 classification을 위해 다음의 데이터를 준다.
   - 10,015개의 training 병변 이미지
   - 1개의 CSV 파일은 10,015개의 진단에 대한 training 데이터 셋을 가지고 있다.

  3) 병변 이미지들은 트레이닝 세트와 테스트 셋으로 상응하게 분할되어 있다.
   - task 1과 task 2를 위한 2294개 / 300개의 이미지
   - task 3을 위한 8015개 / 2000개의 이미지

 (2) Augmentation
  1) 트레이닝 동안, 이미지는 다음과 같이 augmented 된다.
   - 이미지는 수직 및 수평으로 flip 된다.
   - 이미지는 90도, 180도, 270도로 회전 된다.
   - 이미지의 광도는 0.8 ~ 1.5의 범위 내에서 변경 된다.
   - 이미지는 표준 편차 2.5로 Gaussian 블러 된다.

 (3) Scoring
  - task 1과 task 2에서는 필수로 하나 이상의 binary 마스크를 통해 분리 경계 및 병변 특성을 나타내야 한다.
    task 1과 task 2의 목표는 Jaccard index를 극대화 하고 예측하는 것이다.
  - task 3에 대한 예측은 이미지에 대해서 질병을 진단하는 벡터의 값이 되어야 한다.
    task 3의 예측은 multi-class accuracy metrics를 통해 검증 된다.


4. Task1 : 병변 경계 분할
 (1) Configuration
  1) Mask-RCNN의 모델은 아래의 파라미터 값들로 트레이닝 되었다.
   - Number of classes : 2
     Backbone network : ResNet50
     Input image dimensions : 768x768
     RPN Anchor Scales : 32, 64, 128, 256, 512
     Anchors per image : 64
     Mask shape : 56x56
     Train RoIs per image : 128
     Learning Rate : 0.001
     Learning Momentum : 0.9
     Weight Decay : 0.0001
  2) training set는 이미지의 가장 긴 쪽을 따라 768픽셀로 조정되었으며, 768x768 픽셀과 일치하도록 패딩 되었다.
     GPU 메모리에 모델을 맞추기 위해 이미지의 크기는 실험적으로 선택 되었다.
     교육 전, Mask R-CNN 모델은 pretrained 된 COCO 웨이트를 통해 초기 설정 되어 있었다.
     40 번의 epochs 동안, learning rate 0.001로 학습시켰으며, learning momentum은 0.9이다.

 (2) Test results
  - results는 input image, prediction image, ground truth image의 세 개의 이미지이다.
    input image는 실사의 이미지이고, prediction image는 대략적인 형태이며, ground truth image는 대략적인 형태에서
    좀 더 정확도가 추가 된 이미지이다.
  - prediction image가 ground truth image에 비해 부정확한 이유는 mask shape이 56x56으로 고정되어 있기 때문이다.
  - 결과에 대한 테스트는 training data set에 포함되어 있지 않은 이미지들로 진행 된다.
    이 작업에서 score는 ground truth의 Jaccard 지수와 마스크 예측에 대한 평균으로 계산 된다.
    Test results의 score로 0.7902의 값이 나왔다.

 (3) Validation results
  - 이 모델은 또한 validation data를 통해 test를 진행 받는다. 100개의 이미지를 통해 test를 진행 받게 된다.
    internal metrics를 통해 0.789라는 점수가 반환 되었다.


5. Task 2 : 병변 속성 탐지
 (1) Configuration
  - task 1에 대한 Mask-RCNN 모델과 비교 했을 때, task 2의 모델은 'task 2를 위해 구성하는 class'만 다르다.
    병변 경계를 나타내는 클래스 1에서 병변의 특성을 나타내는 클래스 5로 변경 되었다.
  - task 2를 위해 80번의 epochs가 실행 되었다. 

 (2) Test results
  - task 2에 대한 모델에 대한 score를 매기기 위해 평균 Jaccard 지수를 이용한다.
  - task 2에 대한 점수는 만족스럽지 못했다.
    globules : 0.2610
    milia-like cysts : 0.2120
    negative network : 0.3082
    pigment network : 0.3725
    streaks : 0.2462
    평균 : 0.2800
  - 그림 2에서 보는 것과 같이 predicted와 ground truth masks가 제공 되었다.
    시각적 분석을 하는 동안 비슷한 이미지들이 서로 다른 클래스 간에 중첩 되어 Mask-RCNN 메소드가 경계를 정확하게
    감지하지 못했다는 결론을 내릴 수 있었다.
    또한, input layer의 해상도가 병변의 속성을 인식하기에 충분히 높지 않을 수 있다는 생각도 했다.

 (3) Validation results
  - 모델은 validation data(100개의 이미지)를 이용하여 자동으로 test 되었다. 0.409의 점수를 받게 되었는데,
    이 점수는 모든 클래스들에 대한 점수들 보다 높은 점수 였다.


6. Task 3 : 질병 분류
 (1) Hybrid한 접근
  - 이 Task의 training을 위해 일련의 병변 이미지들과, 병의 타입에 대해 설명하는 CSV 파일이 제공되었다.
  - 질병 분류에 대해 'Hybrid한 접근' 방법을 이용 했으며, 그 방법은 아래와 같다.
   1) task 1(병변 경계 탐지)의 모델은 이미지 트레이닝과 Validation set를 위한 병변 마스크를 위해 사용되었다.
   2) step 1 마스크의 모든 픽셀들은 ground truth CSV 파일에 포함 된다.
   3) task 1과 거의 동일한 '질병 이미지와 해당 질병의 마스크' 파라미터 값들을 이용하여 task 2에 대한 솔루션으로 이용했다.
      class에 대한 변화 이외에는 거의 동일한 모델을 이용했다.
   4) 위의 step 3에서 학습된 모델을 이용해서 질병에 대한 분류를 했다.
      input 이미지에 대한 마스크가 7개 포함 되었다.
      (마스크에서 가장 큰 영역이 선택 되면, 그것과 연관된 클래스가 선택되어 모델에 대한 예측을 반환한다.)

 (2) Test results
  - Task 3 모델의 점수는, 예측된 질병이 올바른가에 대한 총 training set의 비율이다.
    점수는 0.8420이었다.
  - 그림 3의 줄임말에 대한 설명은 다음과 같다.
    MEL : Melanoma
    NV : Melanocytic nevus
    BCC : Basal cell carcinoma
    AKIEC : Actinic keratosis / Browens disease
    BKL : Benign keratosis
    DF : Dermatofibroma
    VASC : Vascular lesion
  - 표를 통해 위의 각각의 질병에 대한 각기 다른 점수를 얻은 것을 확인할 수 있다.

 (3) Validation results
  - 모델은 자동으로 validation test를 통해 193개의 이미지로 검사 되었으며, 앞의 점수보다 낮은 0.744의 점수를 얻었다.


<Abnormality Detection and Localization in Chest X-Rays using Deep Convolutional Neural Networks>
1. 논문 주제
 - 흉부 X-Ray는 심장과 폐 부위의 이상을 진단하는 데 널리 사용된다. 
 - 이렇듯 이상을 진단하는 과정을, 자동으로 감지할 수 있으면 실제 진단 프로세스가 크게 향상될 것이다.
 - 데이터의 표준으로는 인디애나 흉부 X-Ray 데이터 세트, JSRT 데이터 세트 및 Shenzhen 데이터 세트를 사용했다.
 - 우리는 '학습된 분류자'를 통해 심근경색이나 폐부종과 같은, 공간적으로 퍼지는 이상 현상을 성공적으로 찾아낼 수 있었다.
 - 딥러닝 기반의 분류와 지역화는 의학계에서 꼭 필요한 분야이다.


2. Introduction
 - 의료용 X-rays는 예상치 못한 병리학적 변형, 비침습적 특성, 경제적 고려 때문에 이용한다.
   X-Ray는 주로 예비 진단 도구로 이용 된다.
 - X-Ray 분석을 위한 CAD(Computer Assisted Detection) 도구를 개발하면, 많은 이점을 얻을 수 있다.
   우선 CAD는 방사선사가 정량적이고 정확한 정보를 바탕으로 진단을 할 수 있도록 도와 준다.
   한 명의 방사선사에게 많은 양의 데이터 양이 주어지면, 방사선사는 동일한 효율로 진단을 하기 어려울 수 있다.
   방사선사 의사가 진단의 질을 유지하기 위해서는, 자동화의 증대가 절실히 필요하다!
 - 그러나, CAD 도구의 정확도는 현재까지 상당히 높은 수준까지 도달하지 못했기 때문에
   현재의 CAD 도구는 대부분 손쉬운 시각화를 제공하는 것 정도의 수준이다.


3. Experiments
 - CXR의 비정상을 분류하기 위해 CNN과 RNN의 연계가 이루어 졌다.
 - 데이터 셋 : 
   Indiana Dataset : 심장 비대, 폐부종, 불투명 및 흉막 삼출과 같은 질병이 있는 이미지로 구성 되었다.
   JSRT Dataset : 일본 방사선 과학회에서 작성한 세트. 이 세트에는 247개의 흉부 X 선이 포함되어 있다.
   Shenzhen Dataset : 광동 의과 대학 병원에서 수집 되었다. 정상과 결핵 두 가지의 범주로 분류 된다.
 - DCN(Deep Convolution Network) : DCN은 다양한 진단 방법으로, 질병 탐지에 있어서 이전의 방법들 보다 훨씬 더 높은
정확도를 달성했다. 대부분의 경우 사람의 능력을 넘어 섰다.
 - AlexNet, VGG-Net, ResNet의 모델을 살펴 보았다.
   이러한 모델 들은 컨볼루션의 layer 수에 따라 더 높은 정확도를 기록하고 있었다. 특히 ResNet을 변형하는 것은 
초인적인 성능을 가져 왔다.
   ResNet-50, ResNet-101 및 ResNet-152의 기능은 각각 res4f, res4b22, res4b35 layer에서 추출 되었다.
 - 모든 DCN 모델은 TensorFlow로 구현 되었으며 0.001의 Adam Optimizer를 사용하여 네트워크화 되었다.


4. Results
 - Cardiomegaly(심장)의 이상에서 표준 DCN을 사용했을 경우의 정확도, AUC, 민감도 및 특성
   Cardiomegaly(심장)의 이상에서 드랍 아웃을 사용하는 경우의 정확도, AUC, 민감도 및 특성
 - 우리는 드랍아웃이 사용 될 때 VGG-16과 AlexNet이 가장 높은 정확도와 AUC를 달성한 다는 것을 알 수 있었다.
   반대로 ResNet-101과 VGG-19와 같은 깊은 모델의 정확도는 4% 포인트 떨어진 다는 것을 알 수 있다.
 - 심천 데이터 세트를 이용한 결핵 탐지를 위한 다양한 방법에 대한 정확도, AUC, 민감도 및 특성이다.
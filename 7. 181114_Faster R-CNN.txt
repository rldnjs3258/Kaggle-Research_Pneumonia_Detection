<팀 커널 브리핑>
Faster R-CNN
 - https://curt-park.github.io/2017-03-17/faster-rcnn/
 - http://bcho.tistory.com/1149
 - IoU : https://inspace4u.github.io/dllab/lecture/2017/09/28/IoU.html
 - RPN : https://m.blog.naver.com/PostView.nhn?blogId=laonple&logNo=220782324594&proxyReferer=https%3A%2F%2Fwww.google.com%2F
 - 멤버 : 서기원
 - 내용 :


1. Faster R-CNN : Towards Real-Time Object Detection with Region Proposal Networks
 (1) Introduction
  - Fast R-CNN은 R-CNN의 복잡한 training/test pipeline(처리 경로)를 통합함으로써 눈에 뛰는 성능향상을 가져왔지만, Real-
time object detector에는 못미치므로 속도면에서 아쉬운 부분이 남아 있다.
  - 이를 개선하기 위해 RPNs가 나왔는데, Fast R-CNN에서 가장 큰 계산부하를 차지하는 region proposal 생성을 새로운 방식
으로 대체하고, 이를 모델 내부로 통합한 것이다.

 (2) Faster R-CNN 구성1 : Conv Layers
  - Conv Layers : Filter + ReLu(Activation 함수) 반복 (Conv Layers = CNN(Conv Net)의 구조 중 일부)
컨볼루셔널 레이어는 입력 데이터로부터 특징을 추출하는 역할을 한다. 즉 컨볼루셔널 레이어는 특징을 추출하는 기능을 하는 필
터(Filter)와, 이 필터의 값을 비선형 값으로 바꾸어 주는 Activation 함수로 이루어진다.
  1) 필터
   - 필터는 그 필터의 입력 데이터에 있는지 없는지를 검출해 주는 함수이다. 예를 들어 고리 모양의 곡선을 검출하는 필터는 
벡터 값들로 행렬에 0으로 채워져 있다가, 고리 모양 부분에만 값이 채워져 있다. 입력 이미지 데이터에 필터를 곱해서 만약 이
미지와 필터가 같은 객체라면 결과로 큰 값이 나오고, 같은 객체가 아니라면 결과로 0에 수렴하는 값이 나온다.
  2) Stride
   - 그렇다면 이 필터를 입력 이미지 데이터에 어떻게 곱할까? 큰 사진 전체에 하나의 큰 필터만 곱할까?
5x5의 원본 이미지가 있을 때, Sliding Window의 방법으로 3x3인 필터를 좌측 상단에서부터 오른쪽으로 한 칸씩 그다음 한 줄을 
내려서 또 오른쪽으로 한 칸씩 가며 특징을 추출한다. 이렇게 필터를 적용하는 간격(움직이는 간격)의 값이 Stride 이며, 필터
를 적용해서 얻어낸 결과를 Feature map이라고 한다.
  3) Padding
   - 앞에서 만들어진 Feature map은 원본의 이미지보다 작아진다. 5x5의 원본 데이터에 3x3의 1 Stride를 적용하면 Feature map
은 3x3으로 작아진다. 필터 적용 후 결과 값이 작아지게 되면 처음에 비해서 특징이 많이 유실 될 수 있다. 아직까지 Feature map
에 충분한 특징이 추출되기 전에, 결과 값이 작아지면 특징이 유실되기 때문이다. 이를 방지하기 위한 방법이 Padding인데, 이는
결과 값이 작아지는 것을 방지하기 위해서 입력값 주위로 0 값을 넣어서 입력 값의 크기를 인위적으로 키워서 결과 값이 작아지
는 것을 방지하는 기법이다. 패딩은 또한 원본 데이터에 0 값을 넣어 특징을 희석하므로 오버피팅도 방지하게 된다!
  4) Activation function
   - 필터들을 통해서 Feature map이 추출되었으면, 이 Feature map에 Activation function을 적용하게 된다. 앞에서 필터를 통
해서 추출한 값이 같은 객체이면 큰 값, 아니라면 0에 수렴하는 값이 나왔다. 이 값이 정량적인 값으로 나오기 때문에, 그 특징
이 데이터 안에 '있다 없다'의 비선형 값으로 바꿔 주는 과정이 필요한데, 이것이 바로 Activation function이다. 이 함수는 값
이 참에 가까우면 1에 가까운 값을, 거짓에 가까우면 0~0.5 사이의 값을 리턴한다. CNN에서는 이 Activation function으로 ReLu
를 이용한다.
  5) Conv Layers
   - 이렇게 컨볼루셔널 filter와 ReLu를 반복적으로 하고 조합하며 특징을 추출하는 것이 컨볼루셔널 레이어이다.
  6) Fully Connected Layer(뉴럴 네트워크)
   - CNN에서 컨볼루셔널 레이어 계층의 레이어들이 다 서로 연결되어 있고, RoI Pooling까지 거친 모습이 Fully Connected Lay
er이다. 여기에 DropOut을 추가하고, Activation function 중 Softmax 함수로 이미지 안에 찾는 객체가 들어있을 확률을 계산하
면 CNN의 끝이다.
  7) FCN(Fully-Convolutional network)
   - 기존의 CNN 네트워크의 뒷단에는 컨볼루셔널 레이어 계층의 레이어들이 다 서로 연결되어 있는 Fully Connected Layer가 
온다.
     하.지.만 RPN의 모델로 Fully Connected Layer를 이용할 수 없다. Conv Layers는 입력 이미지도 3차원 이었고, 출력도 3차원
이기 때문에 Conv Layers는 3차원 이미지를 사용할 수 있다. 하지만 Fully Connected Layers는 1차원 데이터만 입력 받을 수 있
기 때문에 Conv Layers 다음에 FC Layers를 이용하려면 3차원 데이터를 평탄화 해서 입력해야 한다. 이 과정에서 3차원 데이터
의 공간적 정보가 손실된다. Segmentation을 하려면 위치 정보를 알아야 하는데, 이가 불가능해지기 때문에 심각한 문제이다.
     따.라.서 RPN의 모델로 Fully Connected Layer를 이용하지 않는다. 그 대신, Fully Connected Layer의 전 과정인 Conv Layer들
만으로 이루어진 말 그대로, Fully Convolutional Network 과정을 이용한다. 즉 모든 과정을 Conv Layer로 구성 한다면 입력 
이미지도 3차원이고 출력도 3차원 이기 때문에 위치 정보가 손실 되지 않는다. (Fully Connected layer를 1x1 Conv Layer로 간
주 함에 따라 위치 정보를 유지하는 것이다.)
     Faster R-CNN에서 Conv net(Conv Layers)의 과정이 FCN이다.

 (3) Faster R-CNN 구성2 : RPN
  - RPN(Region Proposal Network) : RPN을 이용하여 객체가 있을 만한 영역을 찾는다. FCN으로 만든 최종 feature-map을 RPN의
입력으로 받아들인 후, Anchor Box를 sliding window 하여 Positive label에 필터, stride, padding을 적용하여 256 or 512차원의 
벡터 아웃풋을 만든다. 이 벡터를 Classification(분류), Regression(좌표 생성)을 하는 layer와 연결한다. RPN의 출력 결과로 
Objectness score가 붙은 사각형 객체의 집합이 나온다.
  1) Anchor Box
   - Anchor box는 sliding window를 이용하기 위한 박스이다. 따라서 Anchor Box를 이용해서 Bounding Box를 찾아내므로, Anch
or Box가 Bounding Box의 후보가 되는 상자라고 할 수 있겠다. 다양한 비율/크기의 Anchor box를 한 번에 sliding window로 이동
시키며 window의 위치를 중심으로 feature를 추출해낸다. 이는 image/feature pyramids처럼 image 크기를 조정할 필요가 없으며,
multiple-scaled sliding window처럼 filter 크기를 변경할 필요도 없으므로 계산 효율이 높은 방식이라 할 수 있다. 위 논문에
서는 3가지 크기에 대한 각각 3가지 비율의, 총 9개의 anchor box를 사용했다. 우리 주변의 객체들은 생각보다 비율이 단순해서 
1:1, 1:2, 2:1의 비율만을 이용해도 대부분 찾아낼 수 있다.
     이렇듯 sliding window를 통해서 k개의 object를 추천할 수 있으며, 특정 Anchor가 Positive label이 되는 데에는 다음과 
같은 기준이 있다. 첫째, 가장 높은 IoU를 가지고 있는 Anchor일 것. 둘째, IoU>0.7을 만족하는 Anchor일 것. 셋째, IoU<0.3인 
Anchor는 non-positive anchor로 간주할 것.
  2) Bounding Box
   - Bounding Box : 바운딩 박스의 정의는, 전체 이미지 상에서 박스의 좌측 상단 좌표(x1, y1)과, 우측 하단의 좌표(x2, y2)이
다. 또한 이와 더불어, 바운딩 박스 안에 포함된 사물에 대한 각 클래스 별 신뢰도 점수도 함께 제시해야 한다. 즉 '바운딩 박스
(x1, y1, x2, y2) 안에 클래스 X의 사물이 존재할 가능성이 sX이다'의 식의 결과물이다.
  3) IoU(Intersection over union)
   - IoU(Intersection over union) : 두 영역이 교차되는 부분의 넓이를 합영역의 값으로 나눈 값을 뜻한다. Detection의 문제
에서 예측된 경계 상자와 실제 참값(ground truth) 경계 상자의 IOU를 이용해서 해당 경계 상자의 '정확도'를 알 수 있다. 객체 
검출 모델의 정확도는 모델을 테스트용 데이터 셋에서 실행해본 다음 정밀도-재현율 곡선과 평균 정밀도를 통해 알아볼 수 있는
데, 이 과정에서 IOU의 값이 사용된다.
  4) Cls layer(Classification layer)
   - Cls layer(Classification layer) : 벡터가 나타내는 값이 object인지, object가 아닌지 분류하는 작업이다. k개의 object
후보에 대하여 Cls layer는 object인지 아닌지를 구하기 때문에 2k score이다. 이 layer 에서는 14*14*9*2의 아웃풋을 얻는다. 
(14*14*acnhor box의 개수*score의 개수)
  5) reg layer(Regressor layer)
   - reg layer(Regressor layer) : 후보 영역의 좌표를 만들어 내는 작업이다. reg layer에서는 각각의 object에 대하여 4개의
좌표 (X, Y, W, H) 값을 출력하기 때문에 4k 좌표이다. 이 layer 에서는 14*14*9*4의 아웃풋을 얻는다.(14*14*anchor box의 개수
*각 box의 좌표 표시를 위한 데이터의 개수)

 (4) Faster R-CNN 구성3 : RoI Pooling
  - RoI Pooling : 아래는 Mask-RCNN 강의 정리 내용 참고한 내용. Faster R-CNN에서는 RoI Pooling을, Mask R-CNN에서는 RoI 
Align을 이용한다.
  1) RoI Pooling : RPN을 통해 추출한 다양한 RoI들을 7x7의 고정 사이즈로 만든다. 그 후, Max Pooling을 하기 위해 7x7의 
고정 사이즈를 2x2로 만들어야 하는데 실수 픽셀이기 때문에 정수로 2x2로 자른다. 정수이기 때문에 조금 부정확하지만 2x2로 
잘라진 것을 Max Pooling 하여 가장 큰 값을 뽑아 낸다.
  2) RoI Align : RoI Align은 정확성을 높이기 위해 '반올림 하지 않고' Feature의 픽셀 값을 그대로 가져간다. 따라서 픽셀 
값에 따라 7x7 고정 사이즈로 만들고, 2x2로 정확히 잘라진 것을 한번 더 2x2로 잘라서(Subcells) 픽셀 단위로 4개씩 비교하여 
Max Pooling 한다.

 (5) Faster R-CNN 구조 요약
  - image -> conv layers -> feature maps -> RPN -> RoI pooling -> classifier


2. Mask R-CNN 정리
 - (image -> conv layers -> feature maps -> RPN -> RoI Align -> classifier) -> Mask